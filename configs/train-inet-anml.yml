#
# Current best known config for training an ANML-like model on Mini-ImageNet.
#

# Dataset
dataset: miniimagenet
train_size: 500

# Training Configuration
batch_size: 1
num_batches: 20
train_cycles: 1
val_sample_size: 200
remember_size: 100
remember_only: false
inner_lr: 0.001
outer_lr: 0.001

epochs: 25000
seed: 1

# Model Architecture
model: anml
model_args:
    rln_chs: 256
    nm_chs: 112

# Optimization Configuration
inner_params: [rln, fc]
outer_params: all  # special keyword for "all parameters"
output_layer: fc

eval_steps: [10000, 25000]
eval: !include eval-sweep-inet-anml.yml
