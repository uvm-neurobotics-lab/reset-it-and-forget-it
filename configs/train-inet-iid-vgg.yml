#
# Current best known config for i.i.d. pre-training a larger model on OmniImage.
#

# Dataset
dataset: miniimagenet
train_size: 500
# If you add data augmentation you should add many more epochs.
#augment: true

# Training Configuration
train_method: iid
batch_size: 256
epochs: 30
seed: 1

lobo_rate: 0
lobo_size: 64
output_layer: classifier.linear

# Model Architecture
model: classifier
model_name: vgg16_bn
model_args:
  encoder: vgg16_bn_encoder
  classifier: linear-classifier
  classifier_args: {num_classes: 64}

# Optimization
optimizer: Adam
lr: 3.0e-4
#optimizer: SGD
#optimizer_args:
#  lr: 0.1
#  momentum: 0.9
#  weight_decay: 0.0001
#lr_scheduler: CosineAnnealingLR
#lr_scheduler_args:
#  T_max: 30

# Evaluation
save_freq: 125
eval_steps: [2000, 10000]
eval:
  - no-sgd: !include eval-inet-zero-shot.yml
  - olft: !include eval-sweep-inet-1FC.yml
  - unfrozen: !include eval-sweep-inet-unfrozen.yml
  - iid-olft: !include eval-sweep-inet-iid-1FC.yml
  - iid-unfrozen: !include eval-sweep-inet-iid-unfrozen.yml
